{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5db68ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a87bcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShallowNet:\n",
    "    \n",
    "    def __init__(self, layers_dims, learning_rate = 0.0075, num_iterations = 1000):\n",
    "        self.layers_dims = layers_dims\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iterations = num_iterations\n",
    "        \n",
    "    def relu(self, z):\n",
    "        \n",
    "        a = np.maximun(0,z)\n",
    "        cache = a\n",
    "        return a, cache\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        \n",
    "        a = 1/(1+np.exp(-z))\n",
    "        cache = z\n",
    "        return a, cache\n",
    "    \n",
    "    def initialize_parameters(self):\n",
    "        (n_x, n_h, n_y) = self.layers_dims\n",
    "        np.random.seed(1)\n",
    "        w1 = np.random.randn(n_h, n_x)*0.01\n",
    "        b1 = np.zeros((n_h, 1))\n",
    "        w2 = np.random.randn(n_y, n_x)*0.01\n",
    "        b2 = np.zeros((n_y, 1))\n",
    "        \n",
    "        parameters = ('w1', w1, 'b1' : b1, 'w2', w2, 'b2' : b2)\n",
    "        return parameters\n",
    "    \n",
    "    def linear_forward(self, A, W, b):\n",
    "        \n",
    "        Z = np.dot(W, A) + b\n",
    "        cache = (A, W, b)\n",
    "        return Z, cache\n",
    "    \n",
    "    def linear_activation_forward(self, A_prev, W, b ,activation):\n",
    "        \n",
    "        Z, linear_cache = self.linear_forward(A_prev, W, b)\n",
    "        if activation == 'sigmoid':\n",
    "            A, activation_cache = self.sigmoid(Z)\n",
    "            \n",
    "        cache = (linear_cache, activation_cache)\n",
    "        return A, cache\n",
    "    \n",
    "    def model_forward(self, X, parameters):\n",
    "        \n",
    "        cache = []\n",
    "        A, cache = self.linear_activation_forward(A, parameters['W1'], parameters['b1'], activation = 'relu')\n",
    "        caches.append(cache)\n",
    "        A, cache = self.linear_activation_forward(A, parameters['W2'], parameters['b2'], activation = 'sigmoid')\n",
    "        caches.append(cache)\n",
    "        \n",
    "        return A, caches\n",
    "    \n",
    "    def compute_cost (self, AL, Y):\n",
    "        \n",
    "        m = Y.shape[1]\n",
    "        cost = -(np.sum(np.mutiply(Y,np.log(AL))) + np.sum(np.mutiply(1-Y, np.log(1-AL))))/m\n",
    "        \n",
    "        return np.sqeeze(cost)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        A, _ = self.model_forward(X, self.parameters)\n",
    "        m =  X.shape[1]\n",
    "        n_y = X.shape[0]\n",
    "        pred = np.zeros((n_y,m), dtype = int)\n",
    "        for i in range (m):\n",
    "            for j in range (A.shape[]):\n",
    "                if A[j,i] >= 0.5:\n",
    "                    pred[j,i] = 1\n",
    "                else:\n",
    "                    pred[j,i] = 0\n",
    "                    \n",
    "        return pred\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \n",
    "        A, _ = self.model_forward(X, self.parameters)\n",
    "        return A\n",
    "    \n",
    "    def sigmoid_backward(self, dA, activation_cache):\n",
    "        \n",
    "        Z = activation_cache\n",
    "        A,_ = sigmoid(Z)\n",
    "        \n",
    "        d = np.multiply(A, 1-A)\n",
    "        dZ = np.multiply(dA, d)\n",
    "        return dZ\n",
    "    \n",
    "    def relu_backward(self, dA, activation_cache):\n",
    "        \n",
    "        Z = activation_cache\n",
    "        d = np.int64(Z >= 0)\n",
    "        dZ = np.multiply(dA, d)\n",
    "        \n",
    "        return dZ\n",
    "    \n",
    "    def linear_backward(self, dZ, cache):\n",
    "        A_prev, W, b = cache\n",
    "        m = A_prev.shape[1]\n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6fb7c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3206f2be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62486c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c8fa65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f14a03e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd2a4a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
